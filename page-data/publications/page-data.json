{"componentChunkName":"component---src-pages-publications-js","path":"/publications/","result":{"data":{"allPublicationsJson":{"nodes":[{"title":"Improved Deep Point Cloud Geometry Compression","abstract":"Point clouds have been recognized as a crucial data structure for 3D content and are essential in a number of applications such as virtual and mixed reality, autonomous driving, cultural heritage, etc. In this paper, we propose a set of contributions to improve deep point cloud compression, i.e.: using a scale hyperprior model for entropy coding; employing deeper transforms; a different balancing weight in the focal loss; optimal thresholding for decoding; and sequential model training. In addition, we present an extensive ablation study on the impact of each of these factors, in order to provide a better understanding about why they improve RD performance. An optimal combination of the proposed improvements achieves BD-PSNR gains over G-PCC trisoup and octree of 5.51 (6.50) dB and 6.83 (5.85) dB, respectively, when using the point-to-point (point-to-plane) metric.","URL":"http://arxiv.org/abs/2006.09043","author":[{"family":"Quach","given":"Maurice"},{"family":"Valenzise","given":"Giuseppe"},{"family":"Dufaux","given":"Frederic"}],"issued":{"date-parts":[["2020",6,16]]},"fields":{"issued":"2020-06-16","custom":{"links":[{"name":"arXiv","URL":"https://arxiv.org/abs/2006.09043"},{"name":"Source code","URL":"https://github.com/mauriceqch/pcc_geo_cnn_v2"}],"image":{"src":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACWklEQVQoz0WS3UvTURzGBeuq/oXAGylEpMuIiC4suyisRK0ciHYVlClJJJilXaSFWpNSUZAMY2qiEJUGSjrfcr7kUrd8d1uuuan95l5+e3Gfzs6EzsXhe57nex6+L08c4tgs6/y2WvH5VbweD0tmE4rbTSgcZuSrnlXzCqrPz7ZzC8v6GmoggF/kjvYOsrerEFT9BAI+IpEIcVHBlsZ6buXm4XRtC2ELmsxMdLr2KIXmbDYZJy8RUoOM6QfJy9Ewa/yJV/FwJfEcjWU17If2hLBZ5sftuJyU3i8k90Y2ri0HfR97SE87T09XB5NDBhIPJZCelMq2w0VTXS3pFy8wP/eDnuZOTh8+zoOsAvZVBa9tJiYYUFWKC+9R/qhUAr2fP3H92lXmfhpx2p2kHD1BSX6x5Orr6sjX5LDncWP4Ns6ZI8l0NLRBWGXHZIwJRq/aque0NjdJYHx0lJKiIrYcdjGXIAnxx6goeCy5DzodT0oeynhmbJpT8UmM9AzI9+bsQctBMeAG7Ut0rS0SGBseoqq8jE2bBZdoMy0llafFFZLrfN+G9kWljIfFsrKSLzPU3Q8RWJ1ejglGN9PV0c4b7Su5paVfZqornzFlMBAMhKi4W0bBzTsyeXCgH21NNZubNmyrVgozbtPx+p3IC2OcMP9vWfm7y0DfF9yKIkHjzDRTE+MyXl5YpLmqEY/bIz6qfB/Rs7YSq2ZWP0nv225pofk504GgqCp6rBvr+LxeGe8JD9osG3iEJ70+L4umRcKhEGHhyz92u5ivQ+A+UYjCysISwVBQyOzLDv8BsnJTY7/xLEMAAAAASUVORK5CYII=","aspectRatio":2.2222222222222223,"src":"/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/f9ff4/2020_05_pcc_geo_cnn_v2.png","srcSet":"/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/5224a/2020_05_pcc_geo_cnn_v2.png 200w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/d786d/2020_05_pcc_geo_cnn_v2.png 400w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/f9ff4/2020_05_pcc_geo_cnn_v2.png 800w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/73f08/2020_05_pcc_geo_cnn_v2.png 1200w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/8bb6b/2020_05_pcc_geo_cnn_v2.png 1482w","srcWebp":"/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/b0751/2020_05_pcc_geo_cnn_v2.webp","srcSetWebp":"/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/9e195/2020_05_pcc_geo_cnn_v2.webp 200w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/40a1d/2020_05_pcc_geo_cnn_v2.webp 400w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/b0751/2020_05_pcc_geo_cnn_v2.webp 800w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/a7c53/2020_05_pcc_geo_cnn_v2.webp 1200w,\n/static/c07b8221b44e89ddebe0c9dd8fa9dbd8/ea5df/2020_05_pcc_geo_cnn_v2.webp 1482w","sizes":"(max-width: 800px) 100vw, 800px","presentationWidth":800}}}},"publishedArticle":null}}},{"title":"Folding-based compression of point cloud attributes","abstract":"Existing techniques to compress point cloud attributes leverage either geometric or video-based compression tools. We explore a radically different approach inspired by recent advances in point cloud representation learning. Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we fold a 2D grid onto a point cloud and we map attributes from the point cloud onto the folded 2D grid using a novel optimized mapping method. This mapping results in an image, which opens a way to apply existing image processing techniques on point cloud attributes. However, as this mapping process is lossy in nature, we propose several strategies to refine it so that attributes can be mapped to the 2D grid with minimal distortion. Moreover, this approach can be flexibly applied to point cloud patches in order to better adapt to local geometric complexity. In this work, we consider point cloud attribute compression; thus, we compress this image with a conventional 2D image codec. Our preliminary results show that the proposed folding-based coding scheme can already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC) codec.","URL":"http://arxiv.org/abs/2002.04439","author":[{"family":"Quach","given":"Maurice"},{"family":"Valenzise","given":"Giuseppe"},{"family":"Dufaux","given":"Frederic"}],"issued":{"date-parts":[["2020",2,11]]},"fields":{"issued":"2020-02-11","custom":{"links":[{"name":"arXiv","URL":"http://arxiv.org/abs/2002.04439"},{"name":"Source code","URL":"https://github.com/mauriceqch/pcc_attr_folding"}],"image":{"src":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAC4jAAAuIwF4pT92AAAB+0lEQVQoz02R3U+SARjF+bf6G6qbuqjVSFOBMPSlWCkL1MytFmWbLcdsw1h2w1KklcyVmQT0gjMJXmooiB+lM/nIouL718vLYp6b5zzn4uw551EhIywG8D6+3aBUKhVlvn41Q3h2UuHlckmZ085xNsR5hdeqVYqVKs4Hg+TTkqJVZU3VIKJ/kZ4Tx0hvbPEfjvH7XD9/kp+FYksbu9XHwxtGitWWhEV7Bpd9rLWrDg9/0N9voaNdh1WrJhZ6Tyq9Sbe+F12XnqHui6S+SKx8XMVkMnPVIDBqFjjM5/B4XqDT9WLUdDFpG+JXoYAqkz2gra0T9bl2rKbLTD1xIMXjtF/QYBKuoD59HLvdjj/gR39JYMBsZuzOTYKBAE+nptB0Gugz9nBvZIBoLN6MHJfiuFzP+VMqt05/s7DA3JxXjvxb7rCpz856EENh/pZKctdlJEnCdteGa3qGnZ1t1j5HUdXrdY6isddrNYJLb7FYhxg0dBBa9CoGDvsjenuMcg1q1qRVIsshnjkdCMZraM+ewjUx2rywJhscNS4ViwR9iyy982E0GPgQ8Cna/EuPHH8CoVtPcj3BeiJB9FMEURQZHh7B7XY3DRvI5nJkstnW+9ObW+TyeSLRKPvfDyjIha+tJ9nd22N5ZYXtna8kUym+7e5ykMnIvUvE5Ar+AYW5DZPvcrQAAAAAAElFTkSuQmCC","aspectRatio":2.5316455696202533,"src":"/static/9f720b3fa5032763a50cea91fbb4498f/f9ff4/2020_02_pcc_folding.png","srcSet":"/static/9f720b3fa5032763a50cea91fbb4498f/5224a/2020_02_pcc_folding.png 200w,\n/static/9f720b3fa5032763a50cea91fbb4498f/d786d/2020_02_pcc_folding.png 400w,\n/static/9f720b3fa5032763a50cea91fbb4498f/f9ff4/2020_02_pcc_folding.png 800w,\n/static/9f720b3fa5032763a50cea91fbb4498f/73f08/2020_02_pcc_folding.png 1200w,\n/static/9f720b3fa5032763a50cea91fbb4498f/063af/2020_02_pcc_folding.png 1600w,\n/static/9f720b3fa5032763a50cea91fbb4498f/82865/2020_02_pcc_folding.png 1698w","srcWebp":"/static/9f720b3fa5032763a50cea91fbb4498f/b0751/2020_02_pcc_folding.webp","srcSetWebp":"/static/9f720b3fa5032763a50cea91fbb4498f/9e195/2020_02_pcc_folding.webp 200w,\n/static/9f720b3fa5032763a50cea91fbb4498f/40a1d/2020_02_pcc_folding.webp 400w,\n/static/9f720b3fa5032763a50cea91fbb4498f/b0751/2020_02_pcc_folding.webp 800w,\n/static/9f720b3fa5032763a50cea91fbb4498f/a7c53/2020_02_pcc_folding.webp 1200w,\n/static/9f720b3fa5032763a50cea91fbb4498f/80926/2020_02_pcc_folding.webp 1600w,\n/static/9f720b3fa5032763a50cea91fbb4498f/65305/2020_02_pcc_folding.webp 1698w","sizes":"(max-width: 800px) 100vw, 800px","presentationWidth":800}}}},"publishedArticle":null}}},{"title":"Learning Convolutional Transforms for Lossy Point Cloud Geometry Compression","abstract":"Efficient point cloud compression is fundamental to enable the deployment of virtual and mixed reality applications, since the number of points to code can range in the order of millions. In this paper, we present a novel data-driven geometry compression method for static point clouds based on learned convolutional transforms and uniform quantization. We perform joint optimization of both rate and distortion using a trade-off parameter. In addition, we cast the decoding process as a binary classification of the point cloud occupancy map. Our method outperforms the MPEG reference solution in terms of rate-distortion on the Microsoft Voxelized Upper Bodies dataset with 51.5% BDBR savings on average. Moreover, while octree-based methods face exponential diminution of the number of points at low bitrates, our method still produces high resolution outputs even at low bitrates.","URL":"http://arxiv.org/abs/1903.08548","author":[{"family":"Quach","given":"Maurice"},{"family":"Valenzise","given":"Giuseppe"},{"family":"Dufaux","given":"Frederic"}],"issued":{"date-parts":[["2019",3,20]]},"fields":{"issued":"2019-03-20","custom":{"links":[{"name":"arXiv","URL":"https://arxiv.org/abs/1903.08548"},{"name":"Source code","URL":"https://github.com/mauriceqch/pcc_geo_cnn"},{"name":"Supplementary Material Website","URL":"https://mauriceqch.github.io/pcc_geo_cnn_samples/"},{"name":"Supplementary Material","URL":"https://github.com/mauriceqch/pcc_geo_cnn_samples"}],"image":{"src":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAC4jAAAuIwF4pT92AAACFElEQVQoz42M7UtTYRjGnwoEcU3RkZSVGmFpkdGLomGMMjNTnE6Puk2n2zw7m9tRCSGzpA8VCVlgXyPpv+jvsb27t7OV0Qf99TgrrE89cHFd9/277kcYOz+I57+RLHwnKj1h7EjJWXqqIPOvXTR3sPuLGQcslvta2u3/IxY3P3N0/BW1jhVm1UnO+tYwT61Rp76lWX+Pyb1O42gYLejF4nlDlfs1Z/zvuBjeoFyyVvsM3qBGlWedcscLRGD9E6LdicnqwNvXRpMtgOjyYH4QoM6+gLD6sHTZUAdvc6I/JNk0lX1BTg3PSzZLU6eV4Oh9qgd0RJsDEXq5gTjXQa/iIeCf57nu42ZPP6b2QRruTVDW2o3dpRLSdJ6FprlgfYi5w8bpu2NUXu/BNaWiq35W55xYbnQjpvUlhDjCpWu3UEacXL3STEVNLaKmnuONlxHHzLR33sE+pNDSfJ5yy0mEpYGK+hZEWRW9vTZsA4O0NNUjKqoRHz5uYhtR8GlBlp+sMOnTGHW68aoac/oCY84ptLkwj5dXcMzMorgk8wcIhudRHJMsPlpi+ekq424fQ8oEIpvNkstl2fdUKkU2kyEvZyOfJ51Ol1g6vX2QZSeb+e2yl8+RSiblXZJtqWKxgMhIsLX1hWg0SiwW++PxeLzkkUiklA/PiUSCiOztdw3DoFAolLxYLCJ2d3fZ29sr6XD+X/37fgLgUe5r330h/wAAAABJRU5ErkJggg==","aspectRatio":2.3529411764705883,"src":"/static/9eac4f202f7ec4d87cf376538e329129/f9ff4/2019_pcc_geo_cnn.png","srcSet":"/static/9eac4f202f7ec4d87cf376538e329129/5224a/2019_pcc_geo_cnn.png 200w,\n/static/9eac4f202f7ec4d87cf376538e329129/d786d/2019_pcc_geo_cnn.png 400w,\n/static/9eac4f202f7ec4d87cf376538e329129/f9ff4/2019_pcc_geo_cnn.png 800w,\n/static/9eac4f202f7ec4d87cf376538e329129/73f08/2019_pcc_geo_cnn.png 1200w,\n/static/9eac4f202f7ec4d87cf376538e329129/8cffb/2019_pcc_geo_cnn.png 1280w","srcWebp":"/static/9eac4f202f7ec4d87cf376538e329129/b0751/2019_pcc_geo_cnn.webp","srcSetWebp":"/static/9eac4f202f7ec4d87cf376538e329129/9e195/2019_pcc_geo_cnn.webp 200w,\n/static/9eac4f202f7ec4d87cf376538e329129/40a1d/2019_pcc_geo_cnn.webp 400w,\n/static/9eac4f202f7ec4d87cf376538e329129/b0751/2019_pcc_geo_cnn.webp 800w,\n/static/9eac4f202f7ec4d87cf376538e329129/a7c53/2019_pcc_geo_cnn.webp 1200w,\n/static/9eac4f202f7ec4d87cf376538e329129/e170b/2019_pcc_geo_cnn.webp 1280w","sizes":"(max-width: 800px) 100vw, 800px","presentationWidth":800}}}},"publishedArticle":{"event":"2019 IEEE International Conference on Image Processing (ICIP)","DOI":"10.1109/ICIP.2019.8803413"}}}}]}},"pageContext":{}}}